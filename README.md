üï∞Ô∏è Project originally started in early 2025 and maintained locally until today before being uploaded to GitHub.

# Supervised-and-Preference-Fine-Tuning

Fine-tuning TinyLlama, a lightweight open-source language model, for instruction-following and alignment using both Supervised Fine-Tuning (SFT) and Preference Fine-Tuning (PFT) techniques.
It demonstrates how to:
- Perform Supervised Fine-Tuning (SFT) using high-quality instruction-response pairs.  
- Apply Preference Fine-Tuning (PFT) to align model behavior with human or model-based feedback.  
The goal is to make TinyLlama more helpful, truthful, and instruction-aware while maintaining efficiency for academic and applied research.
